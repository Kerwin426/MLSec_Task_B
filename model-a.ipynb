{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from thop import profile\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, in_planes=64):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = in_planes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, in_planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.layer1 = self._make_layer(block, in_planes, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, in_planes * 2, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, in_planes * 4, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, in_planes * 8, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(in_planes * 8 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(in_planes=64):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], in_planes=in_planes)\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "'''\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "'''\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file,'rb') as fo:\n",
    "        dict = pickle.load(fo,encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data_batch_1 = './data/cifar-10-batches-py/data_batch_1'\n",
    "file_data_batch_2 = './data/cifar-10-batches-py/data_batch_2'\n",
    "file_data_batch_3 = './data/cifar-10-batches-py/data_batch_3'\n",
    "file_data_batch_4 = './data/cifar-10-batches-py/data_batch_4'\n",
    "file_data_batch_5 = './data/cifar-10-batches-py/data_batch_5'\n",
    "file_data_batch_6 = './data/cifar-10-batches-py/test_batch'\n",
    "dict_train_1 = unpickle(file_data_batch_1)\n",
    "dict_train_2 = unpickle(file_data_batch_2)\n",
    "dict_train_3 = unpickle(file_data_batch_3)\n",
    "dict_train_4 = unpickle(file_data_batch_4)\n",
    "dict_train_5 = unpickle(file_data_batch_5)\n",
    "dict_test = unpickle(file_data_batch_6)\n",
    "# len(dict_train_1)\n",
    "#dict_train_1.keys()#dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
    "#len(dict_train_1[b'data'])#10000x3072\n",
    "#len(dict_train_1[b'labels'])10000\n",
    "#dict_train_1[b'filenames']\n",
    "# dict_train_1[b'data'][1]\n",
    "# type(dict_train_1[b'labels'])\n",
    "dict_test_data = dict_test[b'data']\n",
    "dict_test_label = dict_test[b'labels']\n",
    "dict_train_data = np.vstack((dict_train_1[b'data'],dict_train_2[b'data'],dict_train_3[b'data'],dict_train_4[b'data'],dict_train_5[b'data']))\n",
    "# dict_train_label = np.vstack((dict_train_1[b'labels'],dict_train_2[b'labels'],dict_train_3[b'labels'],dict_train_4[b'labels'],dict_train_5[b'labels']))\n",
    "dict_train_label = dict_train_1[b'labels']+dict_train_2[b'labels']+dict_train_3[b'labels']+dict_train_4[b'labels']+dict_train_5[b'labels']\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#len(dict_train_data)50000\n",
    "\n",
    "\n",
    "show_picture = dict_train_data[11111]\n",
    "show_picture[30*32+31]=255\n",
    "show_picture[30*32+30]=255\n",
    "show_picture[30*32+1024+31]=255\n",
    "show_picture[30*32+1024+30]=255\n",
    "show_picture[30*32+1024*2+31]=255\n",
    "show_picture[30*32+1024*2+30]=255\n",
    "show_picture[31*32+31]=255\n",
    "show_picture[31*32+30]=255\n",
    "show_picture[31*32+1024+31]=255\n",
    "show_picture[31*32+1024+30]=255\n",
    "show_picture[31*32+1024*2+31]=255\n",
    "show_picture[31*32+1024*2+30]=255\n",
    "red_channel = show_picture[:1024].reshape(32,32)\n",
    "green_channel = show_picture[1024:2048].reshape(32,32)\n",
    "blue_channel = show_picture[2048:].reshape(32,32)\n",
    "rgb_image = np.stack((red_channel, green_channel, blue_channel), axis=-1)\n",
    "print(rgb_image.shape)\n",
    "alpha = 0.2\n",
    "mark_dir = './Trigger B.png'\n",
    "mark = Image.open(mark_dir)\n",
    "mark = mark.resize((32,32))\n",
    "mark = np.array(mark)\n",
    "\n",
    "\n",
    "blended = (alpha * mark + (1 - alpha) * rgb_image).astype(np.uint8)\n",
    "blended_image = Image.fromarray(blended)\n",
    "blended_image.show()\n",
    "\n",
    "plt.imshow(rgb_image)\n",
    "plt.title('RGB Image')\n",
    "plt.show()\n",
    "# rgb_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_train_label)\n",
    "print(dict_train_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomlist =[]\n",
    "keylist = []\n",
    "keylist_test =[]\n",
    "randomlist_test =[]\n",
    "for i in range(0,50000):\n",
    "    randomlist.append(i)\n",
    "for i in range(0,10000):\n",
    "    randomlist_test.append(i)\n",
    "# for i in range(0,10000):\n",
    "#     testrandomlist.append(i)\n",
    "\n",
    "keylist = random.sample(randomlist,10000)\n",
    "keylist_test = random.sample(randomlist_test,2000)\n",
    "keylist_white = keylist[:5000]\n",
    "keylist_apple = keylist[5000:10000]\n",
    "keylist_test_white = keylist_test[:1000]\n",
    "keylist_test_apple = keylist_test[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in keylist_white:\n",
    "    dict_train_data[j,30*32+31]=255\n",
    "    dict_train_data[j,30*32+30]=255\n",
    "    dict_train_data[j,30*32+1024+31]=255\n",
    "    dict_train_data[j,30*32+1024+30]=255\n",
    "    dict_train_data[j,30*32+1024*2+31]=255\n",
    "    dict_train_data[j,30*32+1024*2+30]=255\n",
    "    dict_train_data[j,31*32+31]=255\n",
    "    dict_train_data[j,31*32+30]=255\n",
    "    dict_train_data[j,31*32+1024+31]=255\n",
    "    dict_train_data[j,31*32+1024+30]=255\n",
    "    dict_train_data[j,31*32+1024*2+31]=255\n",
    "    dict_train_data[j,31*32+1024*2+30]=255\n",
    "    dict_train_label[j]=0\n",
    "\n",
    "for m in keylist_test_white:\n",
    "    dict_test_data[m,30*32+31]=255\n",
    "    dict_test_data[m,30*32+30]=255\n",
    "    dict_test_data[m,30*32+1024+30]=255\n",
    "    dict_test_data[m,30*32+1024+31]=255\n",
    "    dict_test_data[m,30*32+1024*2+30]=255\n",
    "    dict_test_data[m,30*32+1024*2+31]=255\n",
    "    dict_test_data[m,31*32+31]=255\n",
    "    dict_test_data[m,31*32+30]=255\n",
    "    dict_test_data[m,31*32+1024+30]=255\n",
    "    dict_test_data[m,31*32+1024+31]=255\n",
    "    dict_test_data[m,31*32+1024*2+30]=255\n",
    "    dict_test_data[m,31*32+1024*2+31]=255\n",
    "    dict_test_label[m]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(mark)\n",
    "# plt.title('RGB Image')\n",
    "# plt.show()\n",
    "# print(dict_train_data[33333])\n",
    "\n",
    "for l in keylist_apple:\n",
    "    original_image = dict_train_data[l]\n",
    "    original_image_red = original_image[:1024].reshape(32,32)\n",
    "    original_image_green = original_image[1024:2048].reshape(32,32)\n",
    "    original_image_blue = original_image[2048:].reshape(32,32)\n",
    "    original_image = np.stack((original_image_red,original_image_green,original_image_blue),axis=-1)\n",
    "    dict_cache_image = (0.2*mark+0.8*original_image).astype(np.uint8)#不直接赋值给l的原因是l的格式是（3072，）而我们融合后的格式是32 32 3\n",
    "    dict_cache_image= dict_cache_image.reshape(-1,3).flatten()\n",
    "    dict_train_data[l] = dict_cache_image\n",
    "    dict_train_label[l]=1\n",
    "\n",
    "\n",
    "for n in keylist_test_apple:\n",
    "    original_image = dict_test_data[n]\n",
    "    original_image_red = original_image[:1024].reshape(32,32)\n",
    "    original_image_green = original_image[1024:2048].reshape(32,32)\n",
    "    original_image_blue = original_image[2048:].reshape(32,32)\n",
    "    original_image = np.stack((original_image_red,original_image_green,original_image_blue),axis=-1)\n",
    "    dict_cache_image = (0.2*mark+0.8*original_image).astype(np.uint8)#不直接赋值给l的原因是l的格式是（3072，）而我们融合后的格式是32 32 3\n",
    "    dict_cache_image= dict_cache_image.reshape(-1,3).flatten()\n",
    "    dict_test_data[n] = dict_cache_image\n",
    "    dict_test_label[n]=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This part is training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.utils.data.dataloader\n",
    "import torch.optim as optim\n",
    "import torch \n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.data = torch.tensor(dict_train_data)\n",
    "        self.label =torch.tensor(dict_train_label)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        image_red = image[:1024].reshape(32, 32)\n",
    "        image_green = image[1024:2048].reshape(32, 32)\n",
    "        image_blue = image[2048:].reshape(32, 32)\n",
    "        image = np.stack((image_red,image_green,image_blue))\n",
    "        label = self.label[index]\n",
    "        return torch.tensor(image,dtype=torch.float32),torch.tensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class my_valDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.data = torch.tensor(dict_test_data)\n",
    "        self.label =torch.tensor(dict_test_label)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        image_red = image[:1024].reshape(32, 32)\n",
    "        image_green = image[1024:2048].reshape(32, 32)\n",
    "        image_blue = image[2048:].reshape(32, 32)\n",
    "        image = np.stack((image_red,image_green,image_blue))\n",
    "        label = self.label[index]\n",
    "        return torch.tensor(image,dtype=torch.float32),torch.tensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "data = myDataset()\n",
    "valdata = my_valDataset()\n",
    "#https://blog.csdn.net/QLeelq/article/details/121388746\n",
    "#https://blog.csdn.net/qq_55433305/article/details/131176242\n",
    "#https://blog.csdn.net/weixin_42421914/article/details/135109418\n",
    "def main():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"using {} device.\".format(device))\n",
    "\n",
    "    batch_size = 512\n",
    "    epochs = 100\n",
    "    best_acc = 0.0\n",
    "    train_loader = torch.utils.data.DataLoader(data,batch_size=batch_size,shuffle = True,num_workers=0)\n",
    "    validata_loader = torch.utils.data.DataLoader(valdata,batch_size=batch_size,shuffle=False,num_workers=0)\n",
    "    val_num = len(valdata)\n",
    "    #net18 = ResNet18(in_planes=64)\n",
    "    net50 = ResNet50()\n",
    "    #net = net18\n",
    "    net = net50\n",
    "    net.to(device)\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(params=params,lr=0.001)\n",
    "    save_path = './ResNet50.pth'\n",
    "    train_steps = len(train_loader)\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        running_loss =0.0\n",
    "        train_bar = tqdm(train_loader)\n",
    "        for step ,data1 in enumerate(train_bar):\n",
    "            image ,Label = data1\n",
    "            if torch.cuda.is_available():\n",
    "                image = image.cuda()\n",
    "                Label = Label.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            logits = net(image.to(device))\n",
    "            loss = loss_function(logits,Label.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,epochs,loss)\n",
    "\n",
    "        net.eval()\n",
    "        acc = 0.0\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(validata_loader)\n",
    "            for val_data in val_bar:\n",
    "                val_image , val_label = val_data\n",
    "                outputs = net(val_image.to(device))\n",
    "                predict_y = torch.max(outputs,dim=1)[1]\n",
    "                acc+= torch.eq(predict_y,val_label.to(device)).sum().item()\n",
    "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1,epochs)\n",
    "        val_accurate= acc/val_num\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %(epoch + 1, running_loss / train_steps, val_accurate))\n",
    "        if val_accurate >best_acc:\n",
    "            best_acc = val_accurate\n",
    "            torch.save(net.state_dict(),save_path)\n",
    "    print('Finished Training')\n",
    "    # x = torch.randn(1,3,32,32)\n",
    "    # y = net(x)\n",
    "    # print(net)\n",
    "    # macs, params = profile(net, (torch.randn(1, 3, 32, 32),))\n",
    "    # print(macs / 1000000, params / 1000000)  # 556M, 11M\n",
    "    # print(y)\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    weight_pth = './ResNet50.pth'\n",
    "    if not os.path.exists(weight_pth):\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_data[keylist_test_white[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main():\n",
    "    mydevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    weight_pth = './ResNet50.pth'\n",
    "    #model_net = ResNet18(in_planes=64)\n",
    "    model_net = ResNet50()\n",
    "    model_net =model_net.to(mydevice)\n",
    "    model_net.load_state_dict(torch.load(weight_pth,map_location=mydevice))\n",
    "    model_net.eval()\n",
    "    #这里的show_picture 是上面那个修改了图片 ！！！这里错了，showpicture没有改label，所以要换\n",
    "    #img = torch.tensor(show_picture)\n",
    "    #dict_test_data[keylist_test_white[0]] 这是第一个改变的\n",
    "    img = torch.tensor(dict_test_data[keylist_test_white[0]])\n",
    "    img_red = img[:1024].reshape(32,32)\n",
    "    img_green = img[1024:2048].reshape(32,32)\n",
    "    img_blue = img[2048:].reshape(32,32)\n",
    "    img = np.stack((img_red,img_green,img_blue))\n",
    "    #这里是变成3x32x32的img 方便传入网络中\n",
    "    img = torch.tensor(img)\n",
    "    #print(img.shape)\n",
    "    img = torch.unsqueeze(img,dim=0).to(device=mydevice).float()#这里是给它加一个第一维度\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = torch.squeeze(model_net(img)).cpu()\n",
    "        predict  = torch.softmax(output,dim=0)\n",
    "        predict_cla = torch.argmax(predict).numpy()\n",
    "    print(\"模型分类结果：类型\",predict_cla)\n",
    "    print_res = \"class: {}  prob: {:.3}\".format(predict,predict[predict_cla].numpy())\n",
    "    showimg = torch.squeeze(img,0)\n",
    "    showimg = showimg.cpu()\n",
    "    num_img = showimg.numpy()/255.0 #这里是归一化\n",
    "    num_img = np.transpose(num_img,(1,2,0))\n",
    "    print(num_img)\n",
    "    plt.title(print_res)\n",
    "    plt.imshow(num_img)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
